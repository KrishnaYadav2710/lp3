# -*- coding: utf-8 -*-
"""
Created on Fri Oct  7 11:21:13 2022

@author: Admin
"""

# First let's start with calling all the dependencies for this project 
import numpy as np 
import pandas as pd
import math
import matplotlib.pyplot as plt
%matplotlib inline 
import seaborn as sns 

#read data file
train_data = pd.read_csv('G:/dypiemr2/dypiemr22-23/sem_I/BE_I/databse/titanic/train.csv')
train_data.head()

test_data = pd.read_csv('G:/dypiemr2/dypiemr22-23/sem_I/BE_I/databse/titanic/test.csv')
test_data.head()

train_data.isnull().sum()

test_data.isnull().sum()

#There's nothing super special about these IDs, 
#so we will drop them from both the test and train datasets.
train_data.drop('PassengerId', axis = 1, inplace=True)
test_data.drop('PassengerId', axis = 1, inplace=True)

#The names of passenger are no longer necessary and can be dropped.
train_data.drop('Name', axis=1, inplace=True)
test_data.drop('Name', axis = 1, inplace= True)

# pai chart for male/female
train_data['Sex'].value_counts().plot(kind="pie",explode=[0.05 for x in train_data['Sex'].dropna().unique()],autopct='%1.1f%%', shadow=True)

train_data.dtypes

#sex is catogorial hence
# Using map function
train_data['Sex'] = train_data['Sex'].map({'male': 1, 'female': 0})

train_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()

train_data.isnull().sum()
#considarable null values in cabin so drop
train_data.drop('Cabin', axis = 1, inplace = True)
test_data.drop('Cabin', axis= 1, inplace = True)


# repalce age null by mean valu
train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)
train_data.isnull().sum()

# drop emabarked null rows
train_data.dropna(subset=['Embarked'], inplace=True)
train_data.isnull().sum()

train_data.shape

train_data.dtypes


#get count of embarked
train_data.Embarked.value_counts()

# replace original embarked by dummies
train_data=pd.get_dummies(train_data,columns=['Embarked'])
train_data.dtypes

#random forest classifier 
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, ConfusionMatrixDisplay

X = train_data.drop('Survived',axis = 1)
y = train_data[['Survived']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

rf_clf = RandomForestClassifier(max_depth = 4, random_state=42)
rf_clf.fit(X_train, y_train)

print('Max depth', 4)

prediction = rf_clf.predict(X_test)
print('Model accuracy: {0:0.4f}'.format(accuracy_score(y_test, prediction)))

print('Precision score: {0:0.4f}'.format(precision_score(y_test, prediction)))

print(confusion_matrix(y_test, prediction))

feature_names= X.columns.to_list()
importances = rf_clf.feature_importances_

i = 0
while i < len(feature_names):
    print('Feature importance:',feature_names[i], round(importances[i],2)*100, '%')
    i +=1
    print()